---
title: Generational References
subtitle: 2.3x faster than reference counting, unoptimized!
author: Evan Ovadia
date: Jan 5 2021
realm: vision
path: vision/safety-generational-references
layout: annotated
namespace: c-blog m-annotated
---


link to grimoire thing here


# What's Next?

## Stack Allocations

If an object is never moved [# ...or moved only to child calls, and in some cases, only moved to parent calls.] then we can put it on a stack.

Generational memory will have multiple "generational stacks", one for each size class, just like jemalloc and mimalloc have parallel heaps. [# We'll have a stack each for 8b, 16b, 24b, 32b, 48b, 64b, etc. Larger objects will occupy multiple entries.] [# Each stack will use a free-list because we need to retire a slot in the stack once its u48 generation hits 0xFFFFFFFFFFFF.] Because of this, and stack-allocated objects' allocation pattern, it will have cache-friendliness similar to a regular stack.

Additionally, when we identify objects that don't need a generation, they can go on the regular stack, not these generational stacks. [# For example, an iterator might be owned by one local and never moved, and only hand out references that are guaranteed to not outlive the object, so we can guarantee it doesn't need a generation.]

<slice/>


## Inline Objects

We can support objects containing other objects inline. [# For example, in C, a struct can live inside another struct's memory, unless it's a pointer.] The only complication is that inline objects are not right after their allocation's generation, as previously assumed. So, we'll:

 * Add a u16 to the reference, an offset from the object's start to the allocation's generation.
 * Change how we get a generation: instead of just dereferencing the object pointer, subtract the u16 offset from it first.

<slice />


## Hybrid-Generational Memory

The generational reference is only the first step towards hybrid-generational memory, and it already beats reference counting.

Hybrid-generational memory adds two layers of optimization:

 * Static analysis, to skip liveness checks.
 * Scope tethering, to keep an object alive longer.

When hybrid-generational memory is fully realized, we expect it could be as fast as Rust, and almost as fast as C++. [# See [Hybrid-Generational Memory](https://verdagon.dev/blog/hybrid-generational-memory) for some comparison with Rust!]

We're excited about this, because it gives us raw speed with zero unsafety, and keeps the language easy to learn and use.

See [Hybrid-Generational Memory](https://verdagon.dev/blog/hybrid-generational-memory) to learn more, and feel free to swing by the [discord server](https://discord.gg/SNB8yGH) with any questions or ideas!


<slice/>
